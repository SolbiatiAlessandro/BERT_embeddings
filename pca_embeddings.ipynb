{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from bert_serving.client import BertClient\n",
    "from bert_serving.server import BertServer\n",
    "from bert_serving.server.helper import get_args_parser\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_sentences = ['Music is an art form, and cultural activity, whose medium is sound', 'In its most general form, the activities describing music as an art form or cultural activity include the creation of works of music (songs, tunes, symphonies, and so on), the criticism of music, the study of the history of music, and the aesthetic examination of music.', 'There are many types of music, including popular music, traditional music, art music, music written for religious ceremonies and work songs such as chanteys', 'Music can be divided into genres (e.g., country music) and genres can be further divided into subgenres (e.g., country blues and pop country are two of the many country subgenres), although the dividing lines and relationships between music genres are often subtle, sometimes open to personal interpretation, and occasionally controversial.']\n",
    "computer_sentences =  ['A computer is a machine that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming.', 'The first digital electronic calculating machines were developed during World War II. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET (MOS transistor) and monolithic integrated circuit (IC) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s.' 'Peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen).']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = music_sentences + computer_sentences\n",
    "labels = [0 for _ in music_sentences] + [1 for _ in computer_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = 1\n",
    "subset_vec_all_layers = []\n",
    "port = 6006\n",
    "port_out = 6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = [\n",
    "    '-model_dir', '../uncased_L-12_H-768_A-12/',\n",
    "    '-num_worker', '2',\n",
    "    '-port', str(port),\n",
    "    '-port_out', str(port_out),\n",
    "    '-max_seq_len', '20',\n",
    "    # '-client_batch_size', '2048',\n",
    "    '-max_batch_size', '256',\n",
    "    # '-num_client', '1',\n",
    "    '-pooling_strategy', 'REDUCE_MEAN',\n",
    "    '-pooling_layer', '-2',\n",
    "    '-gpu_memory_fraction', '0.2',\n",
    "    '-device','3',\n",
    "]\n",
    "args = get_args_parser().parse_args(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 LAYER ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp58h9qmtm\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp58h9qmtm\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp58h9qmtm\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp58h9qmtm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'3af4c877-cdd1-4678-98ed-2d8545a12b4e'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server config:\n",
      "                        client\t=\t3af4c877-cdd1-4678-98ed-2d8545a12b4e\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpOkN4bU/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpaBTF5H/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmplfj0DR/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpaB32n9/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpFO9a3L/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpGoqElQ/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpgD6vKt/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpfdodZD/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp6v249I/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpKfmLrT/socket\n",
      "           server_current_time\t=\t2020-09-24 15:00:47.879611    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-1]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 15:00:13.872726    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'3af4c877-cdd1-4678-98ed-2d8545a12b4e#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'3af4c877-cdd1-4678-98ed-2d8545a12b4e#2'\n"
     ]
    }
   ],
   "source": [
    "setattr(args, 'pooling_layer', [-1])\n",
    "server = BertServer(args)\n",
    "server.start()\n",
    "print('wait until server is ready...')\n",
    "time.sleep(20)\n",
    "print('encoding...')\n",
    "bc = BertClient(port=port, port_out=port_out, show_server_config=True)\n",
    "layer = bc.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20987064,  0.31956345,  0.25079218, ..., -0.15221317,\n",
       "         0.15055206,  0.29068577],\n",
       "       [-0.02111052,  0.4687631 ,  0.03027946, ..., -0.25198817,\n",
       "        -0.09379932,  0.56720257],\n",
       "       [ 0.27522296,  0.5435899 ,  0.20149453, ...,  0.08233873,\n",
       "         0.13124003,  0.2907262 ],\n",
       "       [ 0.01224182, -0.03252828,  0.0662064 , ..., -0.13583335,\n",
       "         0.2631879 ,  0.32271793],\n",
       "       [-0.16499576,  0.08829265, -0.12111602, ..., -0.26839983,\n",
       "        -0.3567505 ,  0.66461146],\n",
       "       [-0.17282781, -0.03886478, -0.11333249, ..., -0.17703345,\n",
       "        -0.20369813,  0.11287816]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL 12 LAYERS ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpcq2wj9vf\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpcq2wj9vf\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpcq2wj9vf\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpcq2wj9vf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'91618f5d-aeaf-4524-9abe-ed620e2062f3'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'91618f5d-aeaf-4524-9abe-ed620e2062f3'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'91618f5d-aeaf-4524-9abe-ed620e2062f3'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'91618f5d-aeaf-4524-9abe-ed620e2062f3#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'91618f5d-aeaf-4524-9abe-ed620e2062f3#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server config:\n",
      "                        client\t=\t91618f5d-aeaf-4524-9abe-ed620e2062f3\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp4KqYuf/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpuyR9Ec/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp2FC6nk/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpOj0ORk/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpkPGF9p/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpnTwg8r/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp4TP78g/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpaJULrq/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpN0WFnf/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp2nJCQe/socket\n",
      "           server_current_time\t=\t2020-09-24 14:38:25.760683    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-1]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:37:55.435125    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'91618f5d-aeaf-4524-9abe-ed620e2062f3#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'91618f5d-aeaf-4524-9abe-ed620e2062f3#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'91618f5d-aeaf-4524-9abe-ed620e2062f3#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpfqculwg0\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpfqculwg0\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpfqculwg0\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpfqculwg0\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'0dded245-3fcb-414d-9445-092faa92d4fc'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'0dded245-3fcb-414d-9445-092faa92d4fc'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'0dded245-3fcb-414d-9445-092faa92d4fc'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'0dded245-3fcb-414d-9445-092faa92d4fc#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'0dded245-3fcb-414d-9445-092faa92d4fc#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t0dded245-3fcb-414d-9445-092faa92d4fc\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpANoGjP/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp7oKcCI/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpNsstVX/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpvXBNO6/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpt9etAR/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpwaUesm/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpRHpXIq/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpeZ7LGB/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpcc9zuT/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpKYq7MC/socket\n",
      "           server_current_time\t=\t2020-09-24 14:38:52.969214    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-2]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:38:26.670842    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'0dded245-3fcb-414d-9445-092faa92d4fc#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'0dded245-3fcb-414d-9445-092faa92d4fc#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'0dded245-3fcb-414d-9445-092faa92d4fc#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0t44_9su\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0t44_9su\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0t44_9su\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0t44_9su\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'68104a91-9ffa-4e3c-b785-88c3e2d18424'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'68104a91-9ffa-4e3c-b785-88c3e2d18424'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'68104a91-9ffa-4e3c-b785-88c3e2d18424'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'68104a91-9ffa-4e3c-b785-88c3e2d18424#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'68104a91-9ffa-4e3c-b785-88c3e2d18424#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t68104a91-9ffa-4e3c-b785-88c3e2d18424\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpL1ozSL/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpzRcArP/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpLQhhVg/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpRoaiQf/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp6xvRCJ/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpyPcfvY/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpoDrWMK/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp58ww5Y/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpUOP8IQ/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpnqWmLB/socket\n",
      "           server_current_time\t=\t2020-09-24 14:39:19.742429    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-3]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:38:53.643150    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'68104a91-9ffa-4e3c-b785-88c3e2d18424#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'68104a91-9ffa-4e3c-b785-88c3e2d18424#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'68104a91-9ffa-4e3c-b785-88c3e2d18424#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp8m229k8q\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp8m229k8q\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp8m229k8q\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp8m229k8q\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpFW6kpR/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpIpnr12/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpG8XklT/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp3R32cT/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpIfyfbU/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpgfJwlf/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpGlbVYY/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp5qpqoh/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmprzzJi7/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpBmU5rb/socket\n",
      "           server_current_time\t=\t2020-09-24 14:39:47.233134    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-4]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:39:20.434488    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'459e93e8-2ab6-4d94-9f9f-cb6ec9ad4ad6#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpx7sujbhd\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpx7sujbhd\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpx7sujbhd\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpx7sujbhd\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'5ce79d8d-352f-4518-8acf-2999605ba6a5'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'5ce79d8d-352f-4518-8acf-2999605ba6a5'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'5ce79d8d-352f-4518-8acf-2999605ba6a5'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'5ce79d8d-352f-4518-8acf-2999605ba6a5#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'5ce79d8d-352f-4518-8acf-2999605ba6a5#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t5ce79d8d-352f-4518-8acf-2999605ba6a5\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp3LBvA5/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpclEcFM/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp3QzCNI/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpHVNoDh/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpG1YSYL/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpSxzrJ5/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpuV1Jkl/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpEwrFvx/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpF1ffhJ/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpjuht4i/socket\n",
      "           server_current_time\t=\t2020-09-24 14:40:14.615328    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-5]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:39:47.912161    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'5ce79d8d-352f-4518-8acf-2999605ba6a5#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'5ce79d8d-352f-4518-8acf-2999605ba6a5#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'5ce79d8d-352f-4518-8acf-2999605ba6a5#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpp9kah6oi\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpp9kah6oi\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpp9kah6oi\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpp9kah6oi\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'f2f4aaf9-3702-45ec-a054-5781551d6c10'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'f2f4aaf9-3702-45ec-a054-5781551d6c10'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'f2f4aaf9-3702-45ec-a054-5781551d6c10'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'f2f4aaf9-3702-45ec-a054-5781551d6c10#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'f2f4aaf9-3702-45ec-a054-5781551d6c10#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\tf2f4aaf9-3702-45ec-a054-5781551d6c10\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpI7W9TK/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpZQ9XAL/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpW0teJn/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpuOuS8U/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpYomoyx/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpS4GXv7/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpo3MuTG/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmphkEKXS/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpl9mXC6/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpihcLhg/socket\n",
      "           server_current_time\t=\t2020-09-24 14:40:42.169475    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-6]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:40:15.272825    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'f2f4aaf9-3702-45ec-a054-5781551d6c10#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'f2f4aaf9-3702-45ec-a054-5781551d6c10#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'f2f4aaf9-3702-45ec-a054-5781551d6c10#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpejifvcqw\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpejifvcqw\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpejifvcqw\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpejifvcqw\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'6261e291-1172-4a6f-b992-b695a4902b63'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'6261e291-1172-4a6f-b992-b695a4902b63'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'6261e291-1172-4a6f-b992-b695a4902b63'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'6261e291-1172-4a6f-b992-b695a4902b63#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'6261e291-1172-4a6f-b992-b695a4902b63#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t6261e291-1172-4a6f-b992-b695a4902b63\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpPg9Ohx/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpwe1lAP/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpxZVEkL/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpx3rpKw/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpYeSzlZ/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpDLWmVa/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpWUhM1Y/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmphmYTnp/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp7ywy2k/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpg1oNTX/socket\n",
      "           server_current_time\t=\t2020-09-24 14:41:09.008820    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-7]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:40:42.854797    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'6261e291-1172-4a6f-b992-b695a4902b63#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'6261e291-1172-4a6f-b992-b695a4902b63#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'6261e291-1172-4a6f-b992-b695a4902b63#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpab5_w_nl\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpab5_w_nl\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpab5_w_nl\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpab5_w_nl\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'2f109881-b956-4943-b845-e89679f21a21'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'2f109881-b956-4943-b845-e89679f21a21'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'2f109881-b956-4943-b845-e89679f21a21'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'2f109881-b956-4943-b845-e89679f21a21#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'2f109881-b956-4943-b845-e89679f21a21#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t2f109881-b956-4943-b845-e89679f21a21\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpUQ0wLB/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpGSwH17/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpIRyf8e/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpBcKpNc/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp9Lnsem/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp1PNY9y/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpLteqNE/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpeE7DDI/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpYeS78P/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpbYeEn8/socket\n",
      "           server_current_time\t=\t2020-09-24 14:41:35.396735    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-8]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:41:09.630891    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'2f109881-b956-4943-b845-e89679f21a21#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'2f109881-b956-4943-b845-e89679f21a21#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'2f109881-b956-4943-b845-e89679f21a21#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpkhrby30d\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpkhrby30d\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpkhrby30d\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpkhrby30d\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'055cad43-dace-4ff0-9f74-9559ef38fb67'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'055cad43-dace-4ff0-9f74-9559ef38fb67'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'055cad43-dace-4ff0-9f74-9559ef38fb67'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'055cad43-dace-4ff0-9f74-9559ef38fb67#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'055cad43-dace-4ff0-9f74-9559ef38fb67#2'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t055cad43-dace-4ff0-9f74-9559ef38fb67\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp35PSgM/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpQnEE6h/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0pFFgC/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpmlPmKg/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp52G43a/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpltJjXh/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpCFQSrU/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpHYzyUb/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpJk2U42/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp0aJBaI/socket\n",
      "           server_current_time\t=\t2020-09-24 14:42:01.516804    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-9]                          \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:41:35.955322    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'055cad43-dace-4ff0-9f74-9559ef38fb67#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'055cad43-dace-4ff0-9f74-9559ef38fb67#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'055cad43-dace-4ff0-9f74-9559ef38fb67#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpd2i5ux6e\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpd2i5ux6e\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpd2i5ux6e\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpd2i5ux6e\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'c944f0c2-1212-43f5-a587-d8176e8c971f'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'c944f0c2-1212-43f5-a587-d8176e8c971f'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'c944f0c2-1212-43f5-a587-d8176e8c971f'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'c944f0c2-1212-43f5-a587-d8176e8c971f#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'c944f0c2-1212-43f5-a587-d8176e8c971f#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'c944f0c2-1212-43f5-a587-d8176e8c971f#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'c944f0c2-1212-43f5-a587-d8176e8c971f#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'c944f0c2-1212-43f5-a587-d8176e8c971f#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\tc944f0c2-1212-43f5-a587-d8176e8c971f\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmph1iuw2/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpEnaJDZ/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp7yzrAJ/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpeThfxc/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp7ZTa17/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpS1g0iw/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpuwnqck/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpOXd8t6/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpjDee4j/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpATCojh/socket\n",
      "           server_current_time\t=\t2020-09-24 14:42:27.807527    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-10]                         \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:42:02.038668    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpyuwio8oa\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpyuwio8oa\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpyuwio8oa\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpyuwio8oa\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\t3fe6aedc-4fc3-4d9c-8380-f81ec1c19b5c\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpgsrWGM/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp25EWZ6/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpt6dLn9/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmplsU0WU/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpqujkKl/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpzYkLR6/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp2jqu14/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp7qVlky/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpe42XU0/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmp1cqgNd/socket\n",
      "           server_current_time\t=\t2020-09-24 14:42:53.547132    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-11]                         \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:42:28.296732    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ../uncased_L-12_H-768_A-12/bert_config.json\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ../uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
      "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmprxeqak5t\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmprxeqak5t\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:133]:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:136]:start the sink\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait until server is ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:222]:get devices\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:306]:ready\n",
      "W:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:246]:no GPU available, fall back to CPU\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ge:255]:device map: \n",
      "\t\tworker  0 -> cpu\n",
      "\t\tworker  1 -> cpu\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmprxeqak5t\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:_ru:531]:use device cpu, load graph from /var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmprxeqak5t\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:gen:559]:ready and listening!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:164]:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:180]:new config request\treq id: 1\tclient: b'c3b7703f-9ce2-4817-a308-51e3333c70b6'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:348]:send config\tclient b'c3b7703f-9ce2-4817-a308-51e3333c70b6'\n",
      "/Users/lessandro/Coding/AI/BERT/embeddings/venv/lib/python3.7/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=20\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:196]:new encode request\treq id: 2\tsize: 6\tclient: b'c3b7703f-9ce2-4817-a308-51e3333c70b6'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:gen:568]:new job\tsocket: 0\tsize: 6\tclient: b'c3b7703f-9ce2-4817-a308-51e3333c70b6#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:342]:job register\tsize: 6\tjob id: b'c3b7703f-9ce2-4817-a308-51e3333c70b6#2'\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:_ru:543]:job done\tsize: (6, 768)\tclient: b'c3b7703f-9ce2-4817-a308-51e3333c70b6#2'\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:334]:collect b'EMBEDDINGS' b'c3b7703f-9ce2-4817-a308-51e3333c70b6#2' (E:6/T:0/A:6)\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:_ru:357]:send back\tsize: 6\tjob id: b'c3b7703f-9ce2-4817-a308-51e3333c70b6#2'\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:clo: 89]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:274]:shutting down...\n",
      "I:\u001b[32mSINK\u001b[0m:[__i:clo:279]:terminated!\n",
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:481]:shutting down...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding...\n",
      "server config:\n",
      "                        client\t=\tc3b7703f-9ce2-4817-a308-51e3333c70b6\n",
      "                   num_process\t=\t3                             \n",
      "          ventilator -> worker\t=\t['ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpn3CjrT/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmph3nmEO/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpUbXGnk/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpG7KegU/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpxe7DOS/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpbNgSIp/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpu0azZg/socket', 'ipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpTgj0BI/socket']\n",
      "                worker -> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpJAiM9q/socket\n",
      "           ventilator <-> sink\t=\tipc:///var/folders/tt/kktdtxb905n0tqr92f6dnn540000gn/T/tmpVjitK8/socket\n",
      "           server_current_time\t=\t2020-09-24 14:43:19.052887    \n",
      "                    device_map\t=\t[3]                           \n",
      "         num_concurrent_socket\t=\t8                             \n",
      "                     ckpt_name\t=\tbert_model.ckpt               \n",
      "                   config_name\t=\tbert_config.json              \n",
      "                          cors\t=\t*                             \n",
      "                           cpu\t=\tFalse                         \n",
      "                 do_lower_case\t=\tTrue                          \n",
      "            fixed_embed_length\t=\tFalse                         \n",
      "                          fp16\t=\tFalse                         \n",
      "           gpu_memory_fraction\t=\t0.2                           \n",
      "                 graph_tmp_dir\t=\tNone                          \n",
      "              http_max_connect\t=\t10                            \n",
      "                     http_port\t=\tNone                          \n",
      "                  mask_cls_sep\t=\tFalse                         \n",
      "                max_batch_size\t=\t256                           \n",
      "                   max_seq_len\t=\t20                            \n",
      "                     model_dir\t=\t../uncased_L-12_H-768_A-12/   \n",
      "        no_position_embeddings\t=\tFalse                         \n",
      "              no_special_token\t=\tFalse                         \n",
      "                    num_worker\t=\t2                             \n",
      "                 pooling_layer\t=\t[-12]                         \n",
      "              pooling_strategy\t=\t2                             \n",
      "                          port\t=\t6006                          \n",
      "                      port_out\t=\t6007                          \n",
      "                 prefetch_size\t=\t10                            \n",
      "           priority_batch_size\t=\t16                            \n",
      "         show_tokens_to_client\t=\tFalse                         \n",
      "               tuned_model_dir\t=\tNone                          \n",
      "                       verbose\t=\tFalse                         \n",
      "                           xla\t=\tFalse                         \n",
      "            tensorflow_version\t=\t['1', '13', '1']              \n",
      "                python_version\t=\t3.7.5 (default, Oct 22 2019, 10:35:10) \n",
      "[Clang 10.0.1 (clang-1001.0.46.4)]\n",
      "                server_version\t=\t1.10.0                        \n",
      "                 pyzmq_version\t=\t19.0.2                        \n",
      "                   zmq_version\t=\t4.3.2                         \n",
      "             server_start_time\t=\t2020-09-24 14:42:54.028431    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\u001b[33mWORKER-0\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:481]:shutting down...\n",
      "I:\u001b[33mWORKER-1\u001b[0m:[__i:clo:486]:terminated!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:219]:terminated!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done at layer -12\n"
     ]
    }
   ],
   "source": [
    "subset_vec_all_layers = []\n",
    "for pool_layer in range(1, 13):\n",
    "    setattr(args, 'pooling_layer', [-pool_layer])\n",
    "    server = BertServer(args)\n",
    "    server.start()\n",
    "    print('wait until server is ready...')\n",
    "    time.sleep(20)\n",
    "    print('encoding...')\n",
    "    bc = BertClient(port=port, port_out=port_out, show_server_config=True)\n",
    "    subset_vec_all_layers.append(bc.encode(sentences))\n",
    "    bc.close()\n",
    "    server.close()\n",
    "    print('done at layer -%d' % pool_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_vec_all_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of a embedding is N * H where N is number of sentences and H is the hidden layer size\n",
    "\n",
    "subset_vec_all_layers[0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_subset_vec_all_layers = np.stack(subset_vec_all_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embed = [PCA(n_components=2).fit_transform(v) for v in subset_vec_all_layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pca embed shape is N * 2, where N is the number of sentences and 2 is the reduced (768 -> 2) dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_embed[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_pca(embed, vis_alg='PCA', pool_alg='REDUCE_MEAN'):\n",
    "    plt.close()\n",
    "    fig = plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [21, 7]\n",
    "    for idx, ebd in enumerate(embed):\n",
    "        ax = plt.subplot(2, 6, idx + 1)\n",
    "        vis_x = ebd[:, 0]\n",
    "        vis_y = ebd[:, 1]\n",
    "        plt.scatter(vis_x, vis_y, c=labels, cmap=ListedColormap([\"blue\", \"green\"]))\n",
    "        ax.set_title('pool_layer=-%d' % (idx + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.1, right=0.95, top=0.9)\n",
    "    cax = plt.axes([0.96, 0.1, 0.01, 0.3])\n",
    "    fig.suptitle('%s visualization of BERT layers using \"bert-as-service\" (-pool_strategy=%s)' % (vis_alg, pool_alg),\n",
    "                 fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x504 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_pca(pca_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(music_sentences))\n",
    "print(len(computer_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
